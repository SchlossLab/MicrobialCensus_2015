---
output:
  md_document:
    variant: markdown_github
---

```{r, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
opts_chunk$set("dev" = "png")
opts_chunk$set(results = "hold")
opts_chunk$set(fig.show = "hold")
opts_chunk$set(warning = FALSE)
opts_chunk$set(fig.align = "center")
opts_chunk$set(cache = FALSE)

opts_chunk$set(eval = FALSE)
opts_chunk$set(echo = TRUE)
```

# Getting the archaeal sequence data and metadata

## Get data out of ARB

This is redundant with what we saw for the bacterial data, but for completion...

> To create SSU Ref (ARB file), all sequences below 1,200 bases for Bacteria and
> Eukarya and below 900 bases for Archaea or an alignment identity below 70 or an
> alignment quality value below 50 have been removed from SSU Parc. All sequences
> with a Pintail value < 50 or an alignment quality value < 75 have been assigned
> to color group 1 in ARB (red). All Living Tree Project or  StrainInfo
> typestrains have been assigned to color group 2 in ARB (light blue). From
> http://www.arb-silva.de/documentation/release-119/


```{r get_data, engine="bash"}
wget http://www.arb-silva.de/fileadmin/silva_databases/release_119/ARB_files/SSURef_119_SILVA_14_07_14_opt.arb.tgz
wget http://www.arb-silva.de/fileadmin/silva_databases/release_119/ARB_files/SSURef_119_SILVA_14_07_14_opt.arb.tgz.md5
tar xvzf SSURef_119_SILVA_14_07_14_opt.arb.tgz
```

Within ARB, we will exclude color group 1, chloroplasts, and mitochondria.

To get good sequences...

* Go to search window
* Set Search_Fields to "ARB_color" and use "1"; click on the equal sign to make it not equal
* Hit Mark Listed, Unmark Rest button (N=1652440)

The problem with the taxonomies is that the sequences don't all have taxonomies. Need to figure out which taxonomy to base the analysis on. Do the following searches...

* ARB_color != 1 & tax_rdp == "*Archaea*" (N=46146)
* ARB_color != 1 & tax_greengenes == "*Archaea*" (N=19830)
* ARB_color != 1 & tax_slv == "*Archaea*" (N=59240)
* ARB_color != 1 & tax_embl == "*Archaea*" (N=57863)


Let's stick with the archaeal sequences that have an Silva taxonomy and we will
analyze them in Silva space, but we can always go back to the taxonomy provided by
the other systems if we'd like.

* Return to Search and Query window
* Change search field to "ARB_color", enter "1", and click the equal sign to be not-equal
* Change the second search field to "tax_silva" and set it to "*Archaea*"
* Hit "Search"
* Hit Mark Listed Unmark Rest (N=59,240)
* Click "Write to Fields of Listed", select the "remark" field, and enter "good archaea"
* Click "Write"
* In main ARB window go File->Export->Export to external format
* Select Compress -> "Vertical Gaps" and fasta_mothur.eft as the format
* Rename `noname.fasta` to `data/mothur/archaea.fasta`

Now we need the taxonomy information.

* Go Tree -> NDS
* Click "name", "acc", "tax_slv". The "tax_slv" field should have 250 characters
* Unclick everything else
* Click "Close"
* Go File->Export->Export fields
* Set the file name to "archaea.taxonomy" and Column output to "TAB separated"
* Click "SAVE"

Finally, let's save the database by doing File -> Quick Save Changes and then
quit out of ARB.


## Format taxonomy file

The next thing we need to do is to clean up the archaea.taxonomy.nds file
to make it into a proper, mothur compatible archaea.taxonomy file. Now we're
ready to do some R'ing to get the taxonomy file formatted properly...

```{r format_taxonomy}
tax_data <- read.table(file="data/mothur/archaea.taxonomy.nds", sep="\t")

#get the names to match the fasta file
seq_names <- paste(tax_data$V2, tax_data$V1, sep=".")

taxonomy <- gsub(" ", "_", tax_data$V3)  #convert any spaces to underscores
taxonomy <- gsub('\"', '', taxonomy) #remove quote marks

write.table(cbind(seq_names, taxonomy), "data/mothur/archaea.tax", row.names=F,
                                                col.names=F, quote=F, sep="\t")
```



## Get good sequences

Now we need to know the start/end position of the sequences so that we can
make sure the reads overlap the same alignment space.


```{r get_summary, engine="bash", results="hide", echo=TRUE}
mothur "#summary.seqs(fasta=data/mothur/archaea.fasta, processors=12)"
```

```
			Start	End		NBases	Ambigs	Polymer	NumSeqs
Minimum:	1		6806	900		0		4		1
2.5%-tile:	1004	7718	905		0		5		1482
25%-tile:	1006	8794	943		0		5		14811
Median: 	1039	11168	1308	0		5		29621
75%-tile:	1056	11747	1398	0		6		44431
97.5%-tile:	3020	11909	1469	3		8		57760
Maximum:	5159	12877	2962	46		25		59240
Mean:		1270.65	10393.5	1204.49	0.26683	5.53047
# of Seqs:	59240
```


Notes...
* Will want to get rid of sequences with large number of Ns in them and the
ridiculously long homopolymrs - how large?


```{r find_screening_points}
data <- read.table(file="data/mothur/archaea.summary", header=T, row.names=1)
quantile(data$start, probs=seq(0.9,1,0.01))
start <- 3000

quantile(data$end, probs=seq(0,0.1,0.01))
end <- 7800

quantile(data$nbases, probs=seq(0.0,0.1,0.01))
min_length <- 900

quantile(data$ambigs, probs=seq(0.9,1.0,0.01))
max_ambig <- 2

quantile(data$polymer, probs=seq(0.9,1.0,0.01))
max_polymer <- 8

trimmed <- data[data$start <= start & data$end >= end &
                    data$polymer <= max_polymer & data$nbases > min_length &
                    data$ambigs <= max_ambig,]
nrow(trimmed)
summary(trimmed$nbases)
```

Now let's run these parameters using mothur.

```{r screen_data, engine="bash"}
mothur "#screen.seqs(fasta=data/mothur/archaea.fasta, taxonomy=data/mothur/archaea.tax, start=3000, end=7800, maxambig=2, maxhomop=8, processors=8);"
```



## Single cell genomics data

Using 16S rRNA gene sequences from the single cell genomics projects we'd like
to see whether that type of data has had a meaningful impact on the trajectory
of the microbial census. The LSU team scraped these 251 sequences from a
database and have provided them to me as a fasta file. Some of them are quite
short and none of them are aligned. Let's go ahead and align them to the SILVA
alignment and then screen them to keep sequences that overlap with the SILVA
sequences.

```{r single_cell, engine="bash"}
mothur "#set.dir(input=data/mothur, output=data/mothur);
        align.seqs(fasta=single_cell.archaea.fasta, reference=archaea.good.fasta);
        screen.seqs(fasta=current, start=3000, end=7800, maxambig=2, maxhomop=8);
        classify.seqs(fasta=current, reference=archaea.good.fasta, taxonomy=archaea.good.tax, cutoff=80)"
```

Once we run everything through, we see that there were 44 sequences that met our `screen.seqs` criteria.


## EMIRGE sequence data

EMIRGE is a method of either assembling 16S rRNA gene sequences from metagenomic
data or from sheared amplicons. This is a method of generating full-length
sequences using short read technologies. We've identified a handful of studies
that have used EMIRGE to generate these data and that actually made their data
publicly available. Some of these are already in the SILVA database, but many
are only available in supplementary materials or on lab websites. To generate
the pooled fasta and metadata files we run the following. Note that because
we're scraping data out of some supplements these scripts assume that you have
access to the journals...

```{r get_emirge, engine="bash"}
bash code/get_emirge_fasta.sh
bash code/get_emirge_metadata.sh
```

This will bring in 81,616 sequences: 81,608 from bacteria, 7 from archaea, and 1 from a eukaryote. We'll ignore the eukaryote. The `code/get_emirge_fasta.sh` script split the sequences by domain and put the fasta sequences into `data/mothur/` for further processing. We need to process these sequences similar to what we did with the single cell data. Because we're worried about the archaea for this notebook and there are so few, we'll process them slightly differently from the bacterial sequences by aligning them to `archaea.good.fasta`.

```{r process_emirge, engine="bash"}
mothur "#set.dir(input=data/mothur, output=data/mothur);
        align.seqs(fasta=emirge.archaea.fasta, reference=archaea.good.fasta);
        screen.seqs(fasta=current, start=3000, end=7800, maxambig=2, maxhomop=8);
        classify.seqs(fasta=current, reference=archaea.good.fasta, taxonomy=archaea.good.tax, cutoff=80)"
```

Once we run everything through, we see that there were 6 sequences that met our `screen.seqs` criteria.




## Pooling the data

Before we can press on with clustering, we need to clean up the taxonomy files that we generated for the EMIRGE and single cell data a bit. We'll do this with R

```{r tax_clean}
tax_clean <- function(tax_file, out_file){
	tax <- scan(file=tax_file, sep='\n', what="", quiet=T)
	tax_clean <- gsub("\\(\\d*\\);", ";", tax)
	tax_clean <- gsub("unclassified;", "", tax_clean)
	write(tax_clean, file=out_file)
}

tax_clean('data/mothur/single_cell.archaea.good.good.wang.taxonomy', 'data/mothur/single_cell.archaea.taxonomy')

tax_clean('data/mothur/emirge.archaea.good.good.wang.taxonomy', 'data/mothur/emirge.archaea.taxonomy')
```


Now we want to merge the SILVA and single cell genomics 16S rRNA gene sequence
collections. We'll also filter the sequences to overlap in the same alignment
space, unique them, and precluster them...

```{r pool_data, engine="bash"}
cat data/mothur/archaea.good.fasta data/mothur/single_cell.archaea.good.align data/mothur/emirge.archaea.good.align > data/mothur/all_archaea.align
cat data/mothur/archaea.good.tax data/mothur/single_cell.archaea.taxonomy data/mothur/emirge.archaea.taxonomy > data/mothur/all_archaea.taxonomy

mothur "#set.dir(input=data/mothur, output=data/mothur);
        filter.seqs(fasta=all_archaea.align, vertical=T, trump=.);
        unique.seqs();
        pre.cluster(fasta=current, name=current, diffs=5);"

#need to make the taxonomy file match the fasta and names files...
cut -f 1 data/mothur/all_archaea.filter.unique.precluster.names > data/mothur/precluster.accnos
mothur "#set.dir(input=data/mothur/, output=data/mothur/);
        get.seqs(taxonomy=all_archaea.taxonomy, accnos=precluster.accnos)"
```

Now we're ready to cluster the sequences. We'll do it by the classic approach
without any cutoffs and see what we get. Let's start by splitting things at the
phylum level and cluster from there...

```{r cluster_data, engine="bash"}
mothur "#set.dir(input=data/mothur/, output=data/mothur/);
        cluster.split(fasta=all_archaea.filter.unique.precluster.fasta, name=all_archaea.filter.unique.precluster.names, taxonomy=all_archaea.pick.taxonomy, taxlevel=2, classic=T, processors=8)"
```


## Get metadata

We'd like to use some metadata from the database to characterize the changes in
the representation of sequences over time, by environment, methods, etc. The
fields housed within SILVA are available at their [website](http://www.arb-silva.de/fileadmin/arb_web_db/release_115/Fields_description/SILVA_description_of_fields_16_06_2013.htm)
and there is an [FAQ](http://www.arb-silva.de/documentation/faqs/) on their site
as well. There were a number of fields that I didn't think were relevant and
instead focused on 30 fields that I thought could help the cause. I marked these
fields in the NDS feature and extracted them to `archaea_metadata.nds`. We need to
tweak this file slightly in R to get it into a format that we can use.


```{r}
metadata_fields <- c(
    "name", #internal ARB database ID, do not change!
    "acc", #accession number
    "bio_material", #identifier for the biological material from which the nucleic acid sequenced was obtained
    "clone", #clone from which the sequence was obtained
    "clone_lib", #clone library from which the sequence was obtained
    "collected_by", #name of the person who collected the specimen
    "collection_date", #date that the sample/specimen was collected
    "country", #geographical origin of sequenced sample
    "culture_collection", #institution code and identifier for the culture from which the nucleic acid sequenced was obtained, with optional collection code
    "date", #entry creation and update date separated by ;
    "description", #description
    "embl_class", #describes the data class in EMBL, e.g. CON: Constructed, WGS: Whole Genome Shotgun, see www.ebi.ac.uk/ena/about/embl_bank_format
    "env_sample", #identifies sequences derived by direct molecular isolation from a bulk environmental DNA sample (by PCR with or without subsequent cloning of the product, DGGE, or other anonymous methods) with no reliable identification of the source organism. Indicated by ‘yes’ in the ARB files
    "full_name", #organism species
    "host", #natural (as opposed to laboratory) host to the organism from which sequenced molecule was obtained.
    "identified_by", #name of the taxonomist who identified the specimen
    "insdc", #the International Nucleotide Sequence Database Collaboration (INSDC) Project Identifier that has been assigned to the entry
    "isolate", #individual isolate from which the sequence was obtained
    "isolation_source", #describes the physical, environmental and/or local geographical source of the biological sample from which the sequence was derived
    "journal", #reference location
    "lat_lon", #geographical coordinates of the location where the specimen was collected
    "publication_doi", #cross-reference DOI number
    "pubmed_id", #cross-reference Pubmed ID
    "strain", #strain from which the sequence was obtained. (t) or [T]: typestrains, [C]: cultivated, [G]: genomes
    "sub_species", #name of sub-species of organism from which sequence was obtained
    "submit_author", #submission authors from reference location
    "submit_date", #submission date from reference location
    "title", #reference title
    "depth_slv", #depth is the vertical distance below surface, e.g. for sediment or soil samples depth is measured from sediment or soil surface, respectively. Depth can be reported as an interval for subsurface samples.
    "habitat_slv" #habitat description according to EnvO-Lite
)


metadata <- read.table(file="data/mothur/archaea_metadata.nds", sep="\t",
                        stringsAsFactors=FALSE, col.names=metadata_fields,
                        fill=TRUE, na.strings="", quote="")
rownames(metadata) <- paste(metadata$acc, metadata$name, sep=".")
metadata <- metadata[,-c(1,2)]
```

Now we want to read in `archaea.bad.accnos` so that we can figure out which
sequences to cull from the metadata table.

```{r}
if(!"openxlsx" %in% rownames(installed.packages())){
    install.packages("openxlsx")
}
library("openxlsx")

bad_accnos_data <- read.table(file="data/mothur/archaea.bad.accnos",
                    col.names=c("name.accnos", "reason"), stringsAsFactors=F)
bad_accnos <- bad_accnos_data$name.accnos
metadata_good <- metadata[-which(rownames(metadata) %in% bad_accnos),]

categories_sheet <- read.xlsx("data/raw/FinalCategories.xlsx", sheet=1, startRow=1, colNames=TRUE)
categories <- categories_sheet[,1]
names(categories) <- categories_sheet[,2]

categories_sheet_missing <- read.xlsx("data/raw/ExtraCategoriesArchaea.xlsx", sheet=1, startRow=1, colNames=FALSE)
categories_missing <- categories_sheet_missing[,"X1"]
names(categories_missing) <- categories_sheet_missing[,"X2"]

categories <- c(categories, categories_missing)


metadata_good$category <- toupper(categories[metadata_good$isolation_source])

extra <- table(metadata_good$isolation_source[is.na(metadata_good$category)])

if(length(extra) != 0){
    write.table(extra, file="missing.txt", row.names=F, col.names=F, quote=FALSE,  sep="\t")
}

write.table(metadata_good, file="data/mothur/archaea.good.metadata", quote=TRUE, sep="\t")
```

We'd also like to get the metadata from the single cell data. We have an `xlsx` that the LSU group pulled together that we'll read in and concatenate to the end of `archaea.good.metadata`.

```{r}
spread_sheet <- read.xlsx("data/raw/FormattedArchaealMetadata.xlsx", sheet=1, startRow=1, colNames=TRUE)
rownames(spread_sheet) <- spread_sheet$name
spread_sheet <- spread_sheet[,-c(1,2)]

metadata_genome_id <- gsub(".* (P?SCGC \\S*).*", "\\1", spread_sheet$full_name)
metadata_genome_id[metadata_genome_id=="SCGC AAA011-J2"] <- "SCGC AAA011-J02"

#need to fix mapping between genome and gene sequences
fasta <- scan("data/mothur/single_cell.archaea.fasta", what="", quiet=TRUE, sep="\n")
headers <- fasta[grepl(">", fasta)]
seq_numbers <- gsub(">(\\d*) .*", "\\1", headers)
parse_header <- gsub(".* (P?SCGC \\S*) .*", "\\1", headers)
parse_header <- gsub(".*SAG-(\\S*) .*", "SCGC \\1", parse_header)

names(seq_numbers) <- parse_header

#recreate a metadata table using sequence names and spread_sheet
full_spread_sheet <- spread_sheet[names(seq_numbers) %in% metadata_genome_id,]
rownames(full_spread_sheet) <- seq_numbers

bad_accnos_data <- read.table(file="data/mothur/single_cell.archaea.bad.accnos", col.names=c("name.accnos", "reason"),  stringsAsFactors=FALSE)
bad_accnos <- as.character(bad_accnos_data$name.accnos)

spread_sheet_good <- full_spread_sheet[-which(rownames(full_spread_sheet) %in% bad_accnos),]
colnames(spread_sheet_good) <- gsub("\\.", "_", colnames(spread_sheet_good))

spread_sheet_good$date <- "2013-07-25"

write.table(spread_sheet_good[,colnames(metadata_good)], file="data/mothur/archaea.good.metadata", quote=TRUE, sep="\t", col.names=F, append=T)
```

We'd also like to get the metadata from the EMIRGE data. We have an metadata file was created above with `code/get_emirge.metadata.sh` that we'll read in and concatenate to the end of `archaea.good.metadata`.

```{r emirge_metadata}
emirge_metadata <- read.table(file="data/raw/emirge.metadata", row.names=1)
archaea_sequences <- read.table(file="data/mothur/emirge.archaea.taxonomy", stringsAsFactors=FALSE)[1]
archaea_emirge_metadata <- emirge_metadata[archaea_sequences$V1,]

write.table(archaea_emirge_metadata, file="data/mothur/archaea.good.metadata", quote=TRUE, sep="\t", col.names=F, append=T)
```

Let's now take the big metadata file that we have and concatenate on the OTU assignment and taxonomy information:

```{r}
#here we'll read in the list file and extract the OTU assignments for the
# unique, 0.03, 0.05, 0.10, 0.20 cutoffs
list_text <- scan(file="data/mothur/all_archaea.filter.unique.precluster.an.list", sep="\n", what="")[c(2,5,7,12,22)]
names(list_text) <- c("0.00", "0.03", "0.05", "0.10", "0.20")

#let's remove the otu label and the number of OTUs at each cutoff
parseList <- function(line){

	list_otus <- unlist(strsplit(line, "\t"))[-c(1,2)]
	n_otus <- length(list_otus)

	#this function will take the sequence names in an OTU, split them up and then
	#assign them the number of that OTU
	split_otu <- function(counter){
	seq_vector <- unlist(strsplit(list_otus[counter], ","))
	n_seqs <- length(seq_vector)
	otu_number <- rep(counter, n_seqs)
	names(otu_number) <- seq_vector
	otu_number
	}

	#now we get the OTU number for each sequence in the dataset
	unlist(lapply(1:n_otus, split_otu))
}
otu_data <- sapply(list_text, parseList)

#let's get the sequence classification data and remove the confidence score data
taxonomy_file <- read.table(file="data/mothur/all_archaea.taxonomy", header=F, row.names=1, stringsAsFactors=T)
taxonomy_data <- gsub("\\(\\d*\\)", "", taxonomy_file$V2)
names(taxonomy_data) <- rownames(taxonomy_file)


#let's get the metadata file and paste in the OTU and taxonomy data
metadata <- read.table(file="data/mothur/archaea.good.metadata", header=T, stringsAsFactors=FALSE)
metadata <- cbind(metadata, otu_data[as.character(rownames(metadata)),])
metadata$taxonomy <- taxonomy_data[as.character(rownames(metadata))]


#let's make sure all of the category names are upper cased
metadata$category <- toupper(metadata$category)

#correct typos:
metadata$category[metadata$category == 'AQD'] <- 'AQO'
metadata$category[metadata$category == 'AQHS'] <- 'AQH'
metadata$category[metadata$category == 'AQS'] <- 'AQMS'
metadata$category[metadata$category == 'VD'] <- 'BD'
metadata$category[metadata$category == 'BM'] <- 'BI'
metadata$category[metadata$category == 'AH'] <- 'AQH'
metadata$category[metadata$category == 'BDBD'] <- 'BD'

#... and we pool the categories by environment
metadata$environment <- rep(NA, nrow(metadata))
metadata$environment[metadata$category == "AE"] <- "aerosol"
metadata$environment[metadata$category == "OT"] <- "other"
metadata$environment[metadata$category %in% c("AQB", "AQBS", "AQF", "AQFS", "AQH", "AQI", "AQM", "AQMS", "AQO", "AQS")] <- "aquatic"
metadata$environment[metadata$category %in% c("BD", "BF", "BI", "BO", "BP")] <- "built"
metadata$environment[metadata$category %in% c("PO", "PR", "PS")] <- "plant"
metadata$environment[metadata$category %in% c("SA", "SD", "SO", "SP")] <- "soil"
metadata$environment[metadata$category %in% c("ZA", "ZN", "ZO", "ZV")] <- "zoonotic"


#let's flag each sequence to indicate how each was generated
source("code/partition_data.R")
metadata$pcr <- is_pcr(metadata)
metadata$cultured <- is_cultured(metadata)
metadata$single_cell <- is_single_cell(metadata)
metadata$emirge_pcr <- is_emirge_pcr(metadata)
metadata$emirge_metag <- is_emirge_metag(metadata)



#... and we output the metadata file...
write.table(metadata, file="data/process/archaea.v123.metadata", sep="\t")
```

Viola! We'll upload data/process/archaea.v123.metadata to FigShare and start analyzing the data for the paper.
