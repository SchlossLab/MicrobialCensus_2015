---
output:
  md_document:
    variant: markdown_github
---

```{r, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
opts_chunk$set("dev" = "png")
opts_chunk$set(results = "hold")
opts_chunk$set(fig.show = "hold")
opts_chunk$set(warning = FALSE)
opts_chunk$set(fig.align = "center")
opts_chunk$set(cache = FALSE)

opts_chunk$set(eval = FALSE)
opts_chunk$set(echo = TRUE)
```

# Getting the bacterial sequence data and metadata

## Get data out of ARB

> To create SSU Ref (ARB file), all sequences below 1,200 bases for Bacteria and
> Eukarya and below 900 bases for Archaea or an alignment identity below 70 or an
> alignment quality value below 50 have been removed from SSU Parc. All sequences
> with a Pintail value < 50 or an alignment quality value < 75 have been assigned
> to color group 1 in ARB (red). All Living Tree Project or  StrainInfo
> typestrains have been assigned to color group 2 in ARB (light blue). From
> http://www.arb-silva.de/documentation/release-119/


```{r get_data, engine="bash"}
wget http://www.arb-silva.de/fileadmin/silva_databases/release_123/ARB_files/SSURef_123_SILVA_19_07_15_opt.arb.tgz
wget http://www.arb-silva.de/fileadmin/silva_databases/release_123/ARB_files/SSURef_123_SILVA_19_07_15_opt.arb.tgz.md5
tar xvzf SSURef_123_SILVA_19_07_15_opt.arb.tgz         
mv SSURef_123_SILVA_19_07_15_opt.arb SSURef_123_SILVA_19_07_15_opt.arb.tgz.md5 data/references
rm SSURef_123_SILVA_19_07_15_opt.arb.tgz
```

Within ARB, we will exclude color group 1, chloroplasts, and mitochondria.

To get good sequences...

* Go to search window
* Set Search_Fields to "ARB_color" and use "1"; click on the equal sign to make it not equal
* Hit Mark Listed, Unmark Rest button (N=1,652,440)

The problem with the taxonomies is that the sequences don't all have taxonomies. Need to figure out which taxonomy to base the analysis on. Do the following searches...

* ARB_color != 1 & tax_rdp == "Bacteria*" (N=1,376,114)
* ARB_color != 1 & tax_greengenes == "k__Bacteria*" (N=1,119,394)
* ARB_color != 1 & tax_slv == "Bacteria*" (N=1,516,624)
* ARB_color != 1 & tax_embl == "Bacteria*" (N=1,331,557)

Let's stick with the bacterial sequences that have an Silva taxonomy and we will
analyze them in Silva space, but preserve the taxonomy generated by the other
systems. The Silva taxonomy includes mitochondrial and chloroplast 16S rRNA gene
sequences, so we'll need to remove them.

* Return to Search and Query window
* Change search field to "ARB_color", enter "1", and click the equal sign to be not-equal
* Change the second search field to "tax_slv" and set it to "Bacteria*"
* Click "Mark Listed, Unmark Rest"
* Change the first search field to "tax_slv" and set it to "*Chloroplast*", set to "not equal"
* Change the second search field to "tax_slv" and set it to "*Mitochondria*", set to "not equal"
* Set the two Query operators to "and"
* Click "Keep species" and "that match query"
* Hit "Search"
* Hit Mark Listed Unmark Rest (N=1,505,125)
* In main ARB window go File->Export->Export to external format
* Select Compress -> "Vertical Gaps" and fasta_mothur.eft as the format
* Rename `noname.fasta` to `data/mothur/bacteria.fasta`

Now we need the taxonomy information.

* Go Tree -> NDS
* Click "name", "acc", "tax_slv". The "tax_slv" field should have 250 characters
* Unclick everything else
* Click "Close"
* Go File->Export->Export fields
* Set the file name to "data/mothur/bacteria.taxonomy.nds" and Column output to "TAB separated"
* Click "SAVE"

Finally, let's save the database by doing File -> Quick Save Changes and then
quit out of ARB.


## Format taxonomy file

The next thing we need to do is to clean up the bacteria.taxonomy.nds file
to make it into a proper, mothur compatible bacteria.taxonomy file. We'll do
some R'ing to get the taxonomy file formatted properly...

```{r format_taxonomy}
tax_data <- read.table(file="data/mothur/bacteria.taxonomy.nds", sep="\t", stringsAsFactors=FALSE)

#get the names to match the fasta file
seq_names <- paste(tax_data$V2, tax_data$V1, sep=".")

taxonomy <- gsub(" ", "_", tax_data$V3)  #convert any spaces to underscores
taxonomy <- gsub('\"', '', taxonomy) #remove quote marks

write.table(cbind(seq_names, taxonomy), "data/mothur/bacteria.tax", row.names=F,
                                                col.names=F, quote=F, sep="\t")
```



## Get good sequences

Now we need to know the start/end position of the sequences so that we can
make sure the reads overlap the same alignment space.


```{r get_summary, engine="bash", results="hide", echo=TRUE}
mothur "#summary.seqs(fasta=data/mothur/bacteria.fasta, processors=12, outputdir=data/mothur/)"
```

```
				Start   End     NBases  Ambigs  Polymer NumSeqs
Minimum:        1       12530   1200    0       4       1
2.5%-tile:      1003    14538   1282    0       5       37629
25%-tile:       1011    14707   1356    0       5       376282
Median:         1044    14926   1387    0       5       752563
75%-tile:       1048    15514   1455    0       6       1128844
97.5%-tile:     1795    15613   1539    2       7       1467497
Maximum:        5300    17580   3469    64      38      1505125
Mean:   		1099.25 15100.4 1405.16 0.180003        5.50868
# of Seqs:      1505125
```


Notes...
* Will want to get rid of sequences with large number of Ns in them - how large?


```{r find_screening_points}
data <- read.table(file="data/mothur/bacteria.summary", header=T, row.names=1)

quantile(data$start, probs=seq(0.9,1,0.01))
start <- 2000

quantile(data$end, probs=seq(0,0.1,0.01))
end <- 14459

quantile(data$nbases, probs=seq(0.0,0.1,0.01))
min_length <- 1200

quantile(data$ambigs, probs=seq(0.9,1.0,0.01))
max_ambig <- 2

trimmed <- data[data$start <= start & data$end >= end &
                    data$nbases > min_length & data$ambigs <= max_ambig,]

nrow(trimmed) #[1] 1431222

summary(trimmed$nbases)
#Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#1201    1359    1390    1409    1457    3469
```

Now let's run these parameters using mothur.

```{r screen_data, engine="bash"}
mothur "#screen.seqs(fasta=data/mothur/bacteria.fasta, taxonomy=data/mothur/bacteria.tax, start=2000, end=14459, maxambig=2, maxhomop=8, outputdir=data/mothur/, processors=8);"
```



## Single cell genomics data

Using 16S rRNA gene sequences from the single cell genomics projects we'd like
to see whether that type of data has had a meaningful impact on the trajectory
of the microbial census. The LSU team scraped these 251 sequences from a
database and have provided them to me as a fasta file. Some of them are quite
short and none of them are aligned. Let's go ahead and align them to the SILVA
alignment and then screen them to keep sequences that overlap with the SILVA
sequences.

```{r single_cell, engine="bash"}
mothur "#set.dir(output=data/mothur);
        align.seqs(fasta=data/mothur/single_cell.bacteria.fasta, reference=data/mothur/bacteria.good.fasta);
        set.dir(input=data/mothur);
        screen.seqs(fasta=current, start=2000, end=14459, maxambig=2);
        classify.seqs(fasta=current, reference=data/mothur/bacteria.good.fasta, taxonomy=data/mothur/bacteria.good.tax, cutoff=80)"
```

Once we run everything through, we see that there were 199 sequences that met our `screen.seqs` criteria.


## EMIRGE sequence data

EMIRGE is a method of either assembling 16S rRNA gene sequences from metagenomic
data or from sheared amplicons. This is a method of generating full-length
sequences using short read technologies. We've identified a handful of studies
that have used EMIRGE to generate these data and that actually made their data
publicly available. Some of these are already in the SILVA database, but many
are only available in supplementary materials or on lab websites. To generate
the pooled fasta and metadata files we run the following. Note that because
we're scraping data out of some supplements these scripts assume that you have
access to the journals...

```{r get_emirge, engine="bash"}
bash code/get_emirge_fasta.sh
bash code/get_emirge_metadata.sh
```

This will bring in 81,616 sequences: 81,608 from bacteria, 7 from archaea, and 1 from a eukaryote. We'll ignore the eukaryote. The `code/get_emirge_fasta.sh` script split the sequences by domain and put the fasta sequences into `data/mothur/` for further processing. We need to process these sequences similar to what we did with the single cell data.

```{r process_emirge, engine="bash"}
mothur "#set.dir(input=data/mothur, output=data/mothur);
        align.seqs(fasta=data/mothur/emirge.bacteria.fasta, reference=data/references/bacteria.seed.fasta);
        screen.seqs(fasta=current, start=2000, end=14459, maxambig=2);
        classify.seqs(fasta=current, reference=data/mothur/bacteria.good.fasta, taxonomy=data/mothur/bacteria.good.tax, cutoff=80, processors=8)"
```

Once we run everything through, we see that there were 58,975 sequences that met our `screen.seqs` criteria.


## Pooling the data

Before we can press on with clustering, we need to clean up the taxonomy files that we generated for the EMIRGE and single cell data a bit. We'll do this with R

```{r tax_clean}
tax_clean <- function(tax_file, out_file){
	tax <- scan(file=tax_file, sep='\n', what="", quiet=T)
	tax_clean <- gsub("\\(\\d*\\);", ";", tax)
	tax_clean <- gsub("unclassified;", "", tax_clean)
	write(tax_clean, file=out_file)
}

tax_clean('data/mothur/single_cell.bacteria.good.good.wang.taxonomy', 'data/mothur/single_cell.bacteria.taxonomy')

tax_clean('data/mothur/emirge.bacteria.good.good.wang.taxonomy', 'data/mothur/emirge.bacteria.taxonomy')
```

Now we want to merge the SILVA and single cell genomics 16S rRNA gene sequence
collections. We'll also filter the sequences to overlap in the same alignment
space, `unique.seqs` them, and `pre.cluster` them...

```{r pool_data, engine="bash"}
cat data/mothur/bacteria.good.fasta data/mothur/single_cell.bacteria.good.align data/mothur/emirge.bacteria.good.align > data/mothur/all_bacteria.align
cat data/mothur/bacteria.good.tax data/mothur/single_cell.bacteria.taxonomy data/mothur/emirge.bacteria.taxonomy > data/mothur/all_bacteria.taxonomy

mothur "#set.dir(input=data/mothur, output=data/mothur);
        filter.seqs(fasta=all_bacteria.align, vertical=T, trump=., processors=8);
        unique.seqs();
        pre.cluster(fasta=current, name=current, diffs=12);"

#need to make the taxonomy file match the fasta and names files...
cut -f 1 data/mothur/all_bacteria.filter.unique.precluster.names > data/mothur/precluster.accnos
mothur "#set.dir(input=data/mothur, output=data/mothur);
        get.seqs(taxonomy=all_bacteria.taxonomy, accnos=precluster.accnos)"
```




Now we're ready to cluster the sequences. We'll do it by the classic approach
without any cutoffs and see what we get. Let's start by splitting things at the
phylum level and cluster from there...

```{r cluster_data, engine="bash"}
mothur "#set.dir(input=data/mothur, output=data/mothur, seed=1);
	cluster.split(fasta=all_bacteria.filter.unique.precluster.fasta, name=all_bacteria.filter.unique.precluster.names, taxonomy=all_bacteria.pick.taxonomy, splitmethod=classify, classic=T, taxlevel=3, cluster=F, processors=12)
	cluster.split(file=all_bacteria.filter.unique.precluster.file, processors=8, classic=TRUE)"
```


## Get metadata

We'd like to use some metadata from the database to characterize the changes in
the representation of sequences over time, by environment, methods, etc. The
fields housed within SILVA are available at their [website](http://www.arb-silva.de/fileadmin/arb_web_db/release_115/Fields_description/SILVA_description_of_fields_16_06_2013.htm)
and there is an [FAQ](http://www.arb-silva.de/documentation/faqs/) on their site
as well. There were a number of fields that I didn't think were relevant and
instead focused on 30 fields that I thought could help the cause. I marked these
fields in the NDS feature and extracted them to
`data/mothur/bacteria.metadata.nds`. We need to tweak this file slightly in R to
get it into a format that we can use.


```{r}
metadata_fields <- c(
    "name", #internal ARB database ID, do not change!
    "acc", #accession number
    "bio_material", #identifier for the biological material from which the nucleic acid sequenced was obtained
    "clone", #clone from which the sequence was obtained
    "clone_lib", #clone library from which the sequence was obtained
    "collected_by", #name of the person who collected the specimen
    "collection_date", #date that the sample/specimen was collected
    "country", #geographical origin of sequenced sample
    "culture_collection", #institution code and identifier for the culture from which the nucleic acid sequenced was obtained, with optional collection code
    "date", #entry creation and update date separated by ;
    "description", #description
    "embl_class", #describes the data class in EMBL, e.g. CON: Constructed, WGS: Whole Genome Shotgun, see www.ebi.ac.uk/ena/about/embl_bank_format
    "env_sample", #identifies sequences derived by direct molecular isolation from a bulk environmental DNA sample (by PCR with or without subsequent cloning of the product, DGGE, or other anonymous methods) with no reliable identification of the source organism. Indicated by ‘yes’ in the ARB files
    "full_name", #organism species
    "host", #natural (as opposed to laboratory) host to the organism from which sequenced molecule was obtained.
    "identified_by", #name of the taxonomist who identified the specimen
    "insdc", #the International Nucleotide Sequence Database Collaboration (INSDC) Project Identifier that has been assigned to the entry
    "isolate", #individual isolate from which the sequence was obtained
    "isolation_source", #describes the physical, environmental and/or local geographical source of the biological sample from which the sequence was derived
    "journal", #reference location
    "lat_lon", #geographical coordinates of the location where the specimen was collected
    "publication_doi", #cross-reference DOI number
    "pubmed_id", #cross-reference Pubmed ID
    "strain", #strain from which the sequence was obtained. (t) or [T]: typestrains, [C]: cultivated, [G]: genomes
    "sub_species", #name of sub-species of organism from which sequence was obtained
    "submit_author", #submission authors from reference location
    "submit_date", #submission date from reference location
    "title", #reference title
    "depth_slv", #depth is the vertical distance below surface, e.g. for sediment or soil samples depth is measured from sediment or soil surface, respectively. Depth can be reported as an interval for subsurface samples.
    "habitat_slv" #habitat description according to EnvO-Lite
)


metadata <- read.table(file="data/mothur/bacteria.metadata.nds", sep="\t",
						stringsAsFactors=FALSE, col.names=metadata_fields,
						fill=TRUE, na.strings="", quote="")
rownames(metadata) <- paste(metadata$acc, metadata$name, sep=".")
metadata <- metadata[,-c(1,2)]
```

Now we want to read in `bacteria.bad.accnos` so that we can figure out which
sequences to cull from the metadata table.

```{r}
if(!"openxlsx" %in% rownames(installed.packages())){
    install.packages("openxlsx")
}
library("openxlsx")

bad_accnos_data <- read.table(file="data/mothur/bacteria.bad.accnos",
                    col.names=c("name.accnos", "reason"), stringsAsFactors=F)
bad_accnos <- bad_accnos_data$name.accnos
metadata_good <- metadata[-which(rownames(metadata) %in% bad_accnos),]

categories_sheet <- read.xlsx("data/raw/FinalCategories.xlsx", sheet=1, startRow=1, colNames=TRUE)
categories <- categories_sheet[,1]
names(categories) <- categories_sheet[,2]

categories_sheet_missing <- read.xlsx("data/raw/ExtraCategoriesBacteria.xlsx", sheet=1, startRow=1, colNames=FALSE)
categories_missing <- categories_sheet_missing[,"X1"]
names(categories_missing) <- categories_sheet_missing[,"X2"]

categories <- c(categories, categories_missing)


metadata_good$category <- toupper(categories[metadata_good$isolation_source])

extra <- table(metadata_good$isolation_source[is.na(metadata_good$category)])

if(length(extra) != 0){
    write.table(extra, file="missing.txt", row.names=F, col.names=F, sep="\t")
}

write.table(metadata_good, file="data/mothur/bacteria.good.metadata", quote=TRUE, na="NA", sep="\t")
```

We'd also like to get the metadata from the single cell data. We have an `xlsx` that the LSU group pulled together that we'll read in and concatenate to the end of `bacteria.good.metadata`.

```{r}
spread_sheet <- read.xlsx("data/raw/FormattedBacterialMetadata.xlsx", sheet=1, startRow=1, colNames=TRUE)
rownames(spread_sheet) <- spread_sheet$name
spread_sheet <- spread_sheet[,-c(1,2)]

metadata_genome_id <- gsub(".* (P?SCGC \\S*)", "\\1", spread_sheet$full_name)
metadata_genome_id[metadata_genome_id=="SCGC AAA003-L8"] <- "SCGC AAA003-L08"

#need to fix mapping between genome and gene sequences
fasta <- scan("data/mothur/single_cell.bacteria.fasta", what="", quiet=TRUE, sep="\n")
headers <- fasta[grepl(">", fasta)]
seq_numbers <- gsub(">(\\d*) .*", "\\1", headers)
names(seq_numbers) <- gsub(".* (P?SCGC \\S*) .*", "\\1", headers)

#recreate a metadata table using sequence names and spread_sheet
full_spread_sheet <- spread_sheet[names(seq_numbers) %in% metadata_genome_id,]
rownames(full_spread_sheet) <- seq_numbers

# these sequences are missing from fasta file
# metadata_genome_id[! metadata_genome_id %in% names(seq_numbers)]
# probably not a horrible thing since not all genomes could give a 16S rRNA gene
# sequence
#
# [1] "SCGC AAA015-N04" "SCGC AAA536-N21" "SCGC AAA158-B04" "SCGC AAA036F23"
# [5] "SCGC AAA001-B15" "SCGC AAA164-N20" "SCGC AAA536-J20" "SCGC AAA008-P15"
# [9] "SCGC AAA536-G18" "SCGC AAA001-B15"


bad_accnos_data <- read.table(file="data/mothur/single_cell.bacteria.bad.accnos", col.names=c("name.accnos", "reason"),  stringsAsFactors=FALSE)
bad_accnos <- as.character(bad_accnos_data$name.accnos)

spread_sheet_good <- full_spread_sheet[-which(rownames(full_spread_sheet) %in% bad_accnos),]

spread_sheet_good$date <- "2013-07-25"

write.table(spread_sheet_good[,colnames(metadata_good)], file="data/mothur/bacteria.good.metadata", quote=TRUE, na="NA", sep="\t", col.names=F, append=T)
```

We'd also like to get the metadata from the EMIRGE data. We have an metadata file was created above with `code/get_emirge.metadata.sh` that we'll read in and concatenate to the end of `bacteria.good.metadata`.

```{r emirge_metadata}
emirge_metadata <- read.table(file="data/raw/emirge.metadata", row.names=1)
bacteria_sequences <- read.table(file="data/mothur/emirge.bacteria.taxonomy", stringsAsFactors=FALSE)[1]
bacteria_emirge_metadata <- emirge_metadata[bacteria_sequences$V1,]

write.table(bacteria_emirge_metadata, file="data/mothur/bacteria.good.metadata", quote=TRUE, sep="\t", col.names=F, append=T)
```



Let's now take the big metadata file that we have and concatenate on the OTU assignment and taxonomy information:

```{r}
#here we'll read in the list file and extract the OTU assignments for the
# unique, 0.03, 0.05, 0.10, 0.20 cutoffs
list_text <- scan(file="data/mothur/all_bacteria.filter.unique.precluster.an.list", sep="\n", what="")[c(2,5,7,12,22)]
names(list_text) <- c("0.00", "0.03", "0.05", "0.10", "0.20")

#let's remove the otu label and the number of OTUs at each cutoff
parseList <- function(line){

	list_otus <- unlist(strsplit(line, "\t"))[-c(1,2)]
	n_otus <- length(list_otus)

	#this function will take the sequence names in an OTU, split them up and then
	#assign them the number of that OTU
	split_otu <- function(counter){
	seq_vector <- unlist(strsplit(list_otus[counter], ","))
	n_seqs <- length(seq_vector)
	otu_number <- rep(counter, n_seqs)
	names(otu_number) <- seq_vector
	otu_number
	}

	#now we get the OTU number for each sequence in the dataset
	unlist(lapply(1:n_otus, split_otu))
}
otu_data <- sapply(list_text, parseList)

#let's get the sequence classification data and remove the confidence score data
taxonomy_file <- read.table(file="data/mothur/all_bacteria.taxonomy", header=F, row.names=1, stringsAsFactors=T)
taxonomy_data <- gsub("\\(\\d*\\)", "", taxonomy_file$V2)
names(taxonomy_data) <- rownames(taxonomy_file)


#let's get the metadata file and paste in the OTU and taxonomy data
metadata <- read.table(file="data/mothur/bacteria.good.metadata", header=T, stringsAsFactors=FALSE)
metadata <- cbind(metadata, otu_data[as.character(rownames(metadata)),])
metadata$taxonomy <- taxonomy_data[as.character(rownames(metadata))]


#let's make sure all of the category names are upper cased
metadata$category <- toupper(metadata$category)

#correct typos:
metadata$category[metadata$category == 'AF'] <- 'AE'
metadata$category[metadata$category == 'AQBF'] <- 'AQB'
metadata$category[metadata$category == 'AQD'] <- 'AQO'
metadata$category[metadata$category == 'AQHS'] <- 'AQH'
metadata$category[metadata$category == 'AQS'] <- 'AQMS'
metadata$category[metadata$category == 'AWF'] <- 'AQF'
metadata$category[metadata$category == 'DS'] <- 'BS'
metadata$category[metadata$category == 'S'] <- 'SO'
metadata$category[metadata$category == 'SI'] <- 'BI'
metadata$category[metadata$category == 'V'] <- 'BO'
metadata$category[metadata$category == 'VD'] <- 'BD'
metadata$category[metadata$category == 'ZOZO'] <- 'ZO'
metadata$category[metadata$category == 'AH'] <- 'AQH'
metadata$category[metadata$category == 'AQOS'] <- 'AQS'
metadata$category[metadata$category == 'BS'] <- 'BD'
metadata$category[metadata$category == 'AQS'] <- 'AQFS'
metadata$category[metadata$category == 'ZL'] <- 'ZV'
metadata$category[metadata$category == 'SR'] <- 'PR'
metadata$category[metadata$category == 'M'] <- 'AQM'
metadata$category[metadata$category == 'AQFM'] <- 'AQFS'
metadata$category[metadata$category == 'SV'] <- 'ZV'
metadata$category[metadata$category == 'ZI'] <- 'ZA'

#... and we pool the categories by environment
metadata$environment <- rep(NA, nrow(metadata))
metadata$environment[metadata$category == "AE"] <- "aerosol"
metadata$environment[metadata$category == "OT"] <- "other"
metadata$environment[metadata$category %in% c("AQB", "AQBS", "AQF", "AQFS", "AQH", "AQI", "AQM", "AQMS", "AQO", "AQS")] <- "aquatic"
metadata$environment[metadata$category %in% c("BD", "BF", "BI", "BO", "BP")] <- "built"
metadata$environment[metadata$category %in% c("PO", "PR", "PS")] <- "plant"
metadata$environment[metadata$category %in% c("SA", "SD", "SO", "SP")] <- "soil"
metadata$environment[metadata$category %in% c("ZA", "ZN", "ZO", "ZV")] <- "zoonotic"


#let's flag each sequence to indicate how each was generated
source("code/partition_data.R")
metadata$pcr <- is_pcr(metadata)
metadata$cultured <- is_cultured(metadata)
metadata$single_cell <- is_single_cell(metadata)
metadata$emirge_pcr <- is_emirge_pcr(metadata)
metadata$emirge_metag <- is_emirge_metag(metadata)


#... and we output the metadata file...
write.table(metadata, file="data/process/bacteria.v123.metadata", sep="\t")
```

Viola! We'll upload data/process/bacteria.v123.metadata to FigShare and start analyzing the data for the paper.
